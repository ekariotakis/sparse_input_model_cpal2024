{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d13430e",
   "metadata": {},
   "source": [
    "**Check Usage of GPUs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa96e72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d3ed15",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55a3233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import PIL\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "\n",
    "sys.path.append('./mae')\n",
    "!pip3 install timm==0.4.5  # 0.3.2 does not work in Colab\n",
    "\n",
    "import models_mae\n",
    "import mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f805e2",
   "metadata": {},
   "source": [
    "**Set CUDA Device**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d2af5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d0868c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35997287",
   "metadata": {},
   "source": [
    "## 1. Create CLS_DATASET Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bda4b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLS_DATASET(Dataset):\n",
    "\n",
    "    def __init__(self, root, cls_dir, csv_file, transform=None):\n",
    "        self.root = root\n",
    "        self.cls_dir = cls_dir\n",
    "        self.cls_files = [f for f in os.listdir(cls_dir) if f.endswith('.pt')]\n",
    "        self.cls_files = sorted(self.cls_files)\n",
    "    \n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.data = torch.LongTensor(self.data_frame.values.tolist())\n",
    "        self.data = self.data.squeeze()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # load each load_batch_size items\n",
    "        load_batch_size = 50 \n",
    "        cls_idx = index//load_batch_size\n",
    "        cls_vec_name = os.path.join(self.cls_dir, self.cls_files[cls_idx])\n",
    "        cls_vec = torch.load(cls_vec_name)\n",
    "        cls = cls_vec[index%load_batch_size,:].unsqueeze(0)\n",
    "\n",
    "        label = self.data[index]\n",
    "        if self.transform:\n",
    "            cls = self.transform(cls)\n",
    "        return (cls, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfd86a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHOOSE DATASET\n",
    "# dataset = 'CIFAR10'\n",
    "dataset = 'CIFAR100'\n",
    "# dataset = 'RESISC45'\n",
    "# dataset = 'AID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db0bc67",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SEED = 1234\n",
    "SEED = 123\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# mask_ratio = 0.3\n",
    "# mask_ratio = 0.1\n",
    "mask_ratio = 0.5\n",
    "\n",
    "ROOT = '/data/ek58_data/'\n",
    "train_cls_dir = ROOT+'cls_tokens_/'+dataset+'/train_'+str(mask_ratio)+'/data'\n",
    "test_cls_dir = ROOT+'cls_tokens_/'+dataset+'/test_'+str(mask_ratio)+'/data'\n",
    "train_csv_file = ROOT+'cls_tokens_/'+dataset+'/train_'+str(mask_ratio)+'/train_cls_y.csv'\n",
    "test_csv_file = ROOT+'cls_tokens_/'+dataset+'/test_'+str(mask_ratio)+'/test_cls_y.csv'\n",
    "\n",
    "train_data = CLS_DATASET(root=ROOT,\n",
    "                           cls_dir=train_cls_dir,\n",
    "                           csv_file=train_csv_file)\n",
    "\n",
    "test_data = CLS_DATASET(root=ROOT,\n",
    "                           cls_dir=test_cls_dir,\n",
    "                           csv_file=test_csv_file)\n",
    "\n",
    "if dataset == 'CIFAR10':\n",
    "    classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "elif dataset == 'CIFAR100':\n",
    "    classes = range(100)\n",
    "elif dataset == 'RESISC45':\n",
    "    classes = range(45)\n",
    "elif dataset == 'AID':\n",
    "    classes = range(30)\n",
    "    \n",
    "BATCH_SIZE = 64\n",
    "# BATCH_SIZE = 16\n",
    "# BATCH_SIZE = 1\n",
    "\n",
    "train_iterator = data.DataLoader(train_data,\n",
    "#                                  shuffle=False,\n",
    "                                 shuffle=True,\n",
    "                                 batch_size=BATCH_SIZE)\n",
    "\n",
    "test_iterator = data.DataLoader(test_data,\n",
    "                                batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d83be0a",
   "metadata": {},
   "source": [
    "## 2. Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb7a518",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_data[0][0].numel()\n",
    "output_dim = len(classes)\n",
    "\n",
    "hidden_in = 1000\n",
    "# hidden_out = 500\n",
    "hidden_out = 1000\n",
    "\n",
    "model = mlp.MLP(input_dim, output_dim, hidden_in, hidden_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca6a767",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17180710",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1927e611",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "\n",
    "train_loss_vec = []; train_acc_vec = []\n",
    "test_loss_vec = []; test_acc_vec = []\n",
    "for epoch in trange(EPOCHS):\n",
    "    start_time = time.monotonic()\n",
    "\n",
    "    train_loss, train_acc = mlp.train(model, train_iterator, optimizer, criterion, device)\n",
    "    test_loss, test_acc = mlp.evaluate(model, test_iterator, criterion, device)\n",
    "\n",
    "    train_loss_vec.append(train_loss); train_acc_vec.append(train_acc)\n",
    "    test_loss_vec.append(test_loss); test_acc_vec.append(test_acc)\n",
    "\n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = utils.epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\tTest Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7036161f",
   "metadata": {},
   "source": [
    "## 3. Examining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bb8bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_str = 'cls_MLP_' + dataset + '_fixedmask_' + str(mask_ratio) + '_ep_' + str(EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bd6d0f",
   "metadata": {},
   "source": [
    "### ***Save Model Logs***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b080cd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('logs/fixedmask/' + str(mask_ratio) + '/' + model_str + '_train_loss.log', train_loss_vec, fmt='%1.4f')\n",
    "np.savetxt('logs/fixedmask/' + str(mask_ratio) + '/' + model_str + '_test_loss.log', test_loss_vec, fmt='%1.4f')\n",
    "np.savetxt('logs/fixedmask/' + str(mask_ratio) + '/' + model_str + '_train_acc.log', train_acc_vec, fmt='%1.4f')\n",
    "np.savetxt('logs/fixedmask/' + str(mask_ratio) + '/' + model_str + '_test_acc.log', test_acc_vec, fmt='%1.4f')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
